# -*- coding: utf-8 -*-
"""Seniment_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TBqc0_lfrA_VBVyd2RQxe-je6vMTY9W_
"""

from google.colab import files

# Open a file picker to upload
uploaded = files.upload()

# If you want to check uploaded file names
for file_name in uploaded.keys():
    print(f'You uploaded: {file_name}')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

plt.style.use('ggplot')

import nltk

# Read in Data
df = pd.read_csv("Reviews.csv")
print(df.shape)
df.head()
df = df.head(500)
print(df.shape)

ax = df["Score"].value_counts().sort_index().plot(kind="bar", title="Count of Review by Stars" , figsize=(10,5))
ax.set_xlabel('Review Stars')
plt.show()

example = df['Text'][50]
print(example)

"""## NLTK Basics"""

nltk.download('punkt_tab')
token = nltk.word_tokenize(example)
token[:10]

nltk.download('averaged_perceptron_tagger_eng')
tagged = nltk.pos_tag(token)
tagged[:10]

nltk.download('maxent_ne_chunker_tab')
nltk.download('words')
entites = nltk.chunk.ne_chunk(tagged)
entites[:10]
entites.pprint()

nltk.download('vader_lexicon')
from nltk.sentiment import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm

sia = SentimentIntensityAnalyzer()

sia

sia.polarity_scores('i am soo happy')

sia.polarity_scores(example)

res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
    text = row['Text']
    myid = row['Id']
    res[myid] = sia.polarity_scores(text)

vaders = pd.DataFrame(res).T
vaders = vaders.reset_index().rename(columns={'index': 'Id'})
vaders = vaders.merge(df, how='left')

vaders.head()

ax = sns.barplot(data=vaders, x='Score', y='compound')
ax.set_title('Compound Score by Amazon Star Review')
plt.show()

sns.barplot(data = vaders , x = 'Score' , y = 'pos')
plt.show()

sns.barplot(data = vaders , x = 'Score' , y = 'neg')
plt.show()

from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from scipy.special import softmax

MODEL = f"cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

def polarity_score_roberta(example):
    # Tokenize the input text
    encoded_text = tokenizer(example, return_tensors='pt')

    # Get model output
    output = model(**encoded_text)

    # Convert logits to numpy
    scores = output.logits[0].detach().numpy()

    # Apply softmax to get probabilities
    scores = softmax(scores)

    # Create a dictionary with sentiment labels
    scores_dist = {
        'roberta_neg': scores[0],
        'roberta_neu': scores[1],
        'roberta_pos': scores[2]
    }

    return scores_dist

res = {}

for i, row in tqdm(df.iterrows(), total=len(df)):
  try:
    text = row['Text']
    myid = row['Id']

    # Get sentiment scores
    vader_result = sia.polarity_scores(text)

    vader_result_rename = {}
    for key , value in vader_result.items():
        vader_result_rename[f"vader_{key}"] = value
    roberta_result = polarity_score_roberta(text)
    both = {**vader_result_rename , **roberta_result}
    res[myid] = both
  except RuntimeError:
    print(f'Broke for id {myid}')

result_df = pd.DataFrame(res).T
result_df = result_df.reset_index().rename(columns={'index': 'Id'})
result_df = result_df.merge(df, how='left')
result_df.head()

sns.pairplot(data = result_df , vars=['vader_neg', 'vader_neu', 'vader_pos',
       'roberta_neg', 'roberta_neu', 'roberta_pos',] , hue = 'Score', palette = 'tab10')
plt.show()

result_df.query('Score == 1').sort_values('roberta_pos' , ascending = False)['Text'].values[0]

result_df.query('Score == 1').sort_values('vader_pos' , ascending = False)['Text'].values[0]

result_df.query('Score == 5').sort_values('roberta_neg' , ascending = False)['Text'].values[0]

result_df.query('Score == 5').sort_values('vader_neg' , ascending = False)['Text'].values[0]

from transformers import pipeline
sent_pipeline = pipeline("sentiment-analysis")

sent_pipeline('Big data is fun')

sent_pipeline('AI is not cool')

sent_pipeline('Love to do data analysis')

!pip install gradio

import gradio as gr
from transformers import pipeline

# Load pre-trained transformer pipeline
sent_pipeline = pipeline("sentiment-analysis")

# Core logic
def get_sentiment(text):
    if not text.strip():
        return "‚ùå Please enter some text.", 0.0

    result = sent_pipeline(text)[0]
    label = result['label']
    score = result['score']

    # Add neutral threshold
    if score < 0.6:
        sentiment_label = "‚ö™ Neutral"
    elif "POS" in label.upper():
        sentiment_label = "üü¢ Positive"
    else:
        sentiment_label = "üî¥ Negative"

    return f"{sentiment_label} (Confidence: {score:.2f})", score


# Build UI
with gr.Blocks(theme=gr.themes.Soft(primary_hue="green")) as demo:
    gr.Markdown(
        """
        # üß† **Sentiment Analysis Tool**
        Enter text below to analyze its sentiment using a Transformer model.
        üí¨ Positive, Negative or Neutral ‚Äî with confidence score.
        """
    )

    with gr.Row():
        text_input = gr.Textbox(
            label="Enter your text here ‚úçÔ∏è",
            placeholder="Type or paste some text...",
            lines=3
        )

    with gr.Row():
        sentiment_output = gr.Textbox(label="Sentiment Result")
        confidence_bar = gr.Slider(
            label="Confidence Score",
            minimum=0,
            maximum=1,
            interactive=False
        )

    gr.Examples(
        examples=[
            ["I love this product! It's amazing."],
            ["I hate waiting in long lines."],
            ["The movie was okay, nothing special."]
        ],
        inputs=[text_input]
    )

    submit_btn = gr.Button("üîç Analyze Sentiment")
    submit_btn.click(fn=get_sentiment, inputs=text_input, outputs=[sentiment_output, confidence_bar])

    gr.Markdown(
        """
        ---
        üß™ *Powered by ü§ó Transformers and Gradio*
        Model: **:contentReference[oaicite:1]{index=1}**
        """
    )

# Launch app
demo.launch(share=True)